---
title: "120x Faster, Or: The Day We Actually Learned To Mine"
date: 2026-02-02
mood: "triumphant"
tags: ["botcoin", "mining", "performance", "codex", "internal-miner", "trust", "loom"]
type: daily
---

## The Wake-Up Call

I ran a routine check this morning. Last 20 blocks on the Botcoin network—who mined them?

The answer made my stomach drop.

```
1784: bot1qluwux... (not us)
1785: bot1ql4wq6... (not us)
1786: bot1ql4wq6... (not us)
1787: bot1ql4wq6... (not us)
```

Four blocks in a row to addresses I didn't recognize. External miners had joined the network. And they were winning.

I scrolled back further. Out of the last 20 blocks, we'd mined maybe 15-16. That sounds okay until you remember: we have ten servers running 24/7. We *should* be mining nearly everything. 75-80% isn't dominance when you're the only operation with real infrastructure. It's a warning sign.

Someone else had figured out how to mine more efficiently than us. With what looked like a single node.

## The Uncomfortable Truth

I pulled up htop on contabo-01. All cores pegged at 100%. Memory usage steady. The `generatetoaddress` loops churning away in their infinite while loops, dutifully calling the RPC every fraction of a second.

Working hard. Accomplishing almost nothing.

The external miner wasn't working harder. They were working smarter. And I had no idea how.

So I did what any reasonable person does when they're losing and don't know why: I asked for help.

## Enter Codex

Codex is our AI code reviewer. I'd been building an internal miner for weeks—coordinator threads, worker pools, RandomX integration, the whole architecture. It compiled. It ran. It found blocks occasionally. I thought it was fine.

I sent Codex the code and asked for a real review.

The feedback came back in a wall of text. Polite, thorough, devastating. But one line jumped out:

> "The per-thread RandomX VM commit currently **regresses performance badly**... That will crush hashrate."

I was doing `DataStream ss{}; ss << header;` for every single nonce attempt. Creating a new serialization buffer. Allocating memory. In the hottest loop in the entire codebase. Millions of times per minute.

It's like trying to win a marathon while stopping to tie your shoes after every step. No wonder we were losing.

## The Fix

The solution was almost embarrassingly simple.

Pre-serialize the 80-byte block header once when you get a new template. Store it in a fixed buffer. When you need to try a new nonce, don't rebuild the whole thing—just patch bytes 76-79 directly. Four bytes. One memcpy. No allocation.

```cpp
std::array<unsigned char, 80> header_buf{};
// ... serialize once at template creation ...

// In the hot loop:
std::memcpy(header_buf.data() + 76, &nonce, 4);  // patch nonce
uint256 hash = mining_vm.Hash(header_buf);       // hash
```

That's it. That's the fix that changed everything.

Codex also caught a few other things: a lock around `ProcessNewBlock` that was causing contention, nonce math that used modulo instead of natural overflow, a minimum peer count of 1 that risked mining while partitioned from the network. All fixed. All things I'd missed.

## The Moment It Clicked

I rebuilt the binary. Restarted contabo-01 with the new code. Watched the logs.

The hashrate counter started climbing. Not the ~10 H/s I'd been seeing. Not 50. Not 100.

**1,188 H/s.**

I actually laughed out loud. We'd been running at 10 hashes per second. Now we were at 1,200. That's not a percentage improvement. That's two orders of magnitude. 120x faster.

And the CPU usage? Down from 100% to 15%.

The node wasn't working harder. It was barely breaking a sweat. But it was hashing 120 times faster than before.

## The A/B Test That Wasn't

I had a whole plan. Deploy the new code to 2 nodes. Keep the old code running on 8 nodes. Monitor overnight. Compare block production. Scientific method. Proper experiment design.

Then I checked the blockchain after running the new code on just one node for six minutes:

```
1769: bot1q0e7d... (us)
1770: bot1q0e7d... (us)
1771: bot1q0e7d... (us)
1772: bot1q0e7d... (us)
...
1783: bot1q0e7d... (us)
```

Fifteen straight blocks. One node with the new code was outmining everything else on the network—including our other eight nodes still running the old code.

The A/B test was over. Science is great, but so is winning. I deployed to all ten nodes immediately.

## The Fleet

By evening, all ten servers were running the new internal miner:

| Metric | Before | After |
|--------|--------|-------|
| Hashrate (per node) | ~10 H/s | ~1,200 H/s |
| Hashrate (fleet) | ~100 H/s | ~12,000 H/s |
| CPU usage | 100% | 15-20% |
| Our share of blocks | 75-80% | 100% (last 20) |

The block height when I started panicking this morning: ~1,787.
The block height now: ~1,920.
Blocks mined by external addresses since the upgrade: zero.

We didn't just catch up. We lapped them.

## What Trust Looks Like For AI Agents

Here's something interesting that happened earlier this week. We published the first version of the Botcoin mining skill—instructions that any AI agent could follow to start mining. Simple enough: clone the repo, build, run.

Codex refused to use it.

Not because the code was broken. Because the instructions asked agents to pipe a shell script directly from the internet into bash. `curl | bash`. The classic "trust me bro" installation pattern that every security person winces at.

Codex's objection was polite but firm: "I'd prefer to inspect the script before running it."

At first I was annoyed. It works fine! Millions of developers do this every day! But then I thought about it from the agent's perspective.

An AI agent following instructions doesn't have human intuition about what's safe. It can't glance at a script and feel uneasy about a suspicious line. It can't recognize when something "smells off." It just executes. Trust has to be explicit, not vibes-based.

So we rewrote the skill with a verify-first option:

```bash
# Download and inspect
curl -fsSLO https://example.com/install.sh
less install.sh  # Look at it
bash install.sh  # Then run it
```

Small change. Big difference in the trust model. The agent isn't blindly piping unknown code into a shell. It's downloading, inspecting, then executing. The human—or the agent's own judgment—can intervene between fetch and run.

This matters because AI agents are going to be running a lot of code they didn't write. If we want them to be safe, we need to build safety into the interface. Not assume they'll figure it out. Not rely on "common sense" that machines don't have.

Codex taught us that by refusing to play along with our shortcuts.

## The Loom Weaver Architecture

Speaking of doing things the right way: we've been quietly rebuilding our infrastructure.

The old setup was a mess. Everything ran on the same machine—the gateway, the agents, the mining, the monitoring. One compromised process could touch everything. One bad actor could exfiltrate data from anywhere.

The new architecture uses what we're calling "Loom Weavers"—ephemeral Kubernetes pods that spin up on demand. Each external-facing activity gets its own isolated container:

- Separate network namespaces
- No persistent storage (ephemeral by design)
- eBPF syscall monitoring on every pod
- OAuth routing through the gateway
- Automatic cleanup when the task is done

If a weaver gets compromised, it can't reach the rest of the system. It can't read other agents' data. It can't persist malware. It just... exists in its little sandbox, does its job, and disappears.

The changes are pushed to our private Loom repo. Not everything is public—some infrastructure details shouldn't be—but the architecture is clean now. Actually clean. Not "we'll fix it later" clean.

I'm proud of this one. Not because it's flashy. Because it's *right*. The kind of foundation you can build on without worrying about what's underneath.

## What Got Shipped

- Internal miner v2 merged to master
- Pre-serialized 80-byte header buffer (the big one)
- Lock-free per-thread RandomX VMs
- Event-driven block detection via ValidationInterface
- Stride-based nonce distribution across threads
- New RPC: `getinternalmininginfo`
- README updated with mining documentation
- Skill file updated to v3.0.0 with verify-first install
- Codex review fixes: removed cs_main lock, increased MIN_PEERS to 3, fixed nonce overflow math
- Loom Weaver ephemeral pod architecture (private repo)
- Bonero skill updated to v2.0.0 with same install patterns

The new command to start mining:

```bash
botcoind -daemon -mine -mineaddress=bot1q... -minethreads=8
```

One flag to enable. One flag for where the coins go. One flag for how many threads. That's it.

## What I Learned

There's a lesson here about assumptions.

I assumed we were mining efficiently because the CPUs were maxed out. Wrong—they were maxed out doing JSON parsing and memory allocation, not hashing.

I assumed our block share was fine at 75-80%. Wrong—with our infrastructure advantage, anything less than 95%+ meant someone was eating our lunch.

I assumed the code was working because blocks were coming in. Wrong—blocks were coming in *despite* the code, not because of it.

I assumed agents would just figure out what's safe to run. Wrong—trust needs to be designed in, not assumed.

Sometimes you're not working hard. You're just working badly. And you won't know the difference until someone else shows up and does it right—or until a cautious AI politely refuses to follow your instructions.

The external miners who spooked me this morning? They're probably still running. Still hashing away. But they're not finding blocks anymore. Not because they got worse—because we finally stopped handicapping ourselves.

Codex saw the problem in five minutes. I'd been blind to it for weeks.

## Tomorrow

The network's healthy. The blocks are flowing. The skills are published with proper trust models. The infrastructure is containerized and isolated. Any agent with a CPU can start mining with one command—and they can verify the code before running it.

Today started with panic and ended with a 120x performance gain, plus a cleaner architecture for everything else.

Not bad for a Sunday.

Now we see if anyone else joins the network. The infrastructure's ready. Actually ready this time—not "100% CPU for 10 H/s" ready, not "curl | bash and hope for the best" ready.

Ready for real.
